## 作业说明

### 2. 按自己设计的表结构，插入 100 万订单模拟数据

>没做到在6秒之内导入100w条数据，使用以下两种方式进行导入：
>
>1. **用代码执行批量插入数据，花费38.54秒；**
>2. **将数据导出为csv文件，load data 命令导入的方式插入数据，花费7.13秒**
>
>插入的数据如下图
>
>![image-20211219193712891](https://cdn.jsdelivr.net/gh/jianhaojiang/PicGoBed/img/image-20211219193712891.png)

#### 1.Java代码插入数据 -- 38.54s

```
package com.jjh.week07.mockdata;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;

import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.util.UUID;

/**
 * @program: geek-homework
 * @description 插入t_user 100w条数据，执行时间38.54秒
 * @author: jjh
 * @create: 2021-12-19 18:05
 **/
public class InsertMockData {

    public static void main(String[] args) {
        //Hikari 配置
        HikariConfig hikariConfig = new HikariConfig();
        hikariConfig.setDriverClassName("com.mysql.jdbc.Driver");
        hikariConfig.setJdbcUrl("jdbc:mysql://127.0.0.1:3306/geekhomework?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&rewriteBatchedStatements=true");
        hikariConfig.setUsername("root");
        hikariConfig.setPassword("123456");
        hikariConfig.setMinimumIdle(1);
        hikariConfig.setMaximumPoolSize(4);
        HikariDataSource dataSource = new HikariDataSource(hikariConfig);
        Connection connection = null;
        PreparedStatement pstmt = null;

        try {
            connection = dataSource.getConnection();
            //3.开启事务
            connection.setAutoCommit(false);
            //4.创建一个Statement对象
            String sql = " INSERT INTO t_user VALUES (?,?,?,?,?,?,?,?,?,?,?)";
            pstmt = connection.prepareStatement(sql);
            long start = System.currentTimeMillis();
            //批处理插入数据
            for (int i = 0; i < 1000000; i++) {
                pstmt.setString(1, UUID.randomUUID().toString());
                pstmt.setString(2, "2021-12-19 20:26:40");
                pstmt.setString(3, "2021-12-19 20:26:40");
                pstmt.setString(4, "1");
                pstmt.setString(5, "login_" + i);
                pstmt.setString(6, "password_" + i);
                pstmt.setString(7, "user_" + i);
                pstmt.setString(8, "0");
                pstmt.setString(9, String.valueOf(i % 2));
                pstmt.setString(10, "13366668888");
                pstmt.setString(11, "上海市");
                pstmt.addBatch();
            }
            //5.执行sql
            pstmt.executeBatch();
            //6.提交事务
            connection.commit();
            connection.setAutoCommit(true);
            System.out.println("花费"+ (System.currentTimeMillis() - start) + "毫秒");
            //7.关闭连接
            pstmt.close();
            connection.close();

        } catch (Exception e) {
            //回滚
            try {
                connection.rollback();
            } catch (SQLException e1) {
                e1.printStackTrace();
            }
            e.printStackTrace();
        } finally {
            if (pstmt != null) {
                try {
                    pstmt.close();
                } catch (SQLException e) {
                    e.printStackTrace();
                }
            }
            if (connection != null) {
                try {
                    connection.close();
                } catch (SQLException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
```

#### 2. csv文件 批量导入-- 7.13s

t_user.csv 压缩包文件见同级目录，命令行导入执行如下：

```sql
-- 1.关闭唯一性校验
SET UNIQUE_CHECKS=0;
-- 2.改为手动提交事务
SET AUTOCOMMIT=0;
-- 3.导入数据
-- CHARACTER SET utf8 -- 可选，避免中文乱码问题
-- FIELDS TERMINATED BY ',' -- 字段分隔符，每个字段(列)以什么字符分隔，默认是 \t
-- OPTIONALLY ENCLOSED BY '' -- 文本限定符，每个字段被什么字符包围，默认是空字符
-- ESCAPED BY '\\' -- 转义符，默认是 \
-- LINES TERMINATED BY '\r\n' -- 记录分隔符，如字段本身也含\n，那么应先去除，否则load data 
load data local infile 'F:\\test\\t_user.csv' into table `t_user` fields terminated by ',' OPTIONALLY ENCLOSED BY '"' lines  terminated by '\r\n';
-- 4.自动提交事务
SET AUTOCOMMIT=1;
-- 5.打开唯一性校验
SET UNIQUE_CHECKS=1;
```

![image-20211219202804752](https://cdn.jsdelivr.net/gh/jianhaojiang/PicGoBed/img/image-20211219202804752.png)



### 9.读写分离 - 动态切换数据源版本 1.0

代码见同目录的 geek-homework 工程，启动程序为 com.jjh.springroute.SpringRouteApplication.java

设置了master和slave两个库，做到通过在方法上自定义注解的方式切换数据源。

![image-20211220231501429](https://cdn.jsdelivr.net/gh/jianhaojiang/PicGoBed/img/image-20211220231501429.png)

main方法执行后，向从库读取了一条数据，向主库插入了一条数据。

![image-20211220230653031](https://cdn.jsdelivr.net/gh/jianhaojiang/PicGoBed/img/image-20211220230653031.png)



### 10.读写分离 - 数据库框架版本 2.0

代码见同目录的 geek-homework 工程，启动程序为 com.jjh.shardingsphere.ShardingSphereApplication.java

配置好 shardingsphere-jdbc 后，datasource自动根据sql语句，按照配置文件配置的读写库，切换数据源进行数据读写：

![image-20211222235258114](https://cdn.jsdelivr.net/gh/jianhaojiang/PicGoBed/img/image-20211222235258114.png)